
## ¿Qué es el Clustering?

Por definición, el clustering es una técnica de aprendizaje no supervisado que agrupa datos similares en conjuntos llamados clústeres.

Es como ordenar una caja de juguetes. Imagina que tienes muchos juguetes diferentes y quieres organizarlos. Naturalmente, pondrías los carros juntos, las muñecas juntas, y así sucesivamente. En datos, el clustering hace algo similar: agrupa datos que son parecidos entre sí.

#### Función en la manipulación de datos:

- Descubrir patrones y estructuras ocultas en los datos
- Segmentar datos para análisis más específicos
- Reducir la complejidad de grandes conjuntos de datos
- Detectar anomalías o valores atípicos

#### Consideraciones para realizar clustering:

- Selección de características relevantes
- Normalización de datos si es necesario
- Elección del número apropiado de clústeres
- Selección de la medida de distancia adecuada
## Ejemplo Práctico: Conjunto de Datos Iris

Vamos a usar las flores Iris como ejemplo. Tenemos medidas de 150 flores de tres especies diferentes:
- Longitud del sépalo
- Ancho del sépalo
- Longitud del pétalo
- Ancho del pétalo

Nuestro objetivo es ver si podemos agrupar estas flores solo por sus medidas, sin saber de antemano a qué especie pertenecen.

## Métodos de Clustering en Orange

a) K-means:
   - Es como dividir a los estudiantes en grupos para un proyecto.
   - Decides cuántos grupos quieres (por ejemplo, 3 para las 3 especies de Iris).
   - Orange agrupa las flores basándose en qué tan parecidas son sus medidas.

b) Clustering Jerárquico:
   - Es como hacer un árbol genealógico de las flores.
   - Orange comienza con cada flor por separado y va juntando las más parecidas.
   - Al final, tienes un "árbol" que muestra cómo se relacionan todas las flores.

## Visualizaciones en Orange

a) Scatter Plot (Gráfico de Dispersión):
   - Es como un mapa donde cada flor es un punto.
   - Flores parecidas estarán cerca una de otra.
   - Diferentes colores muestran diferentes grupos.

b) Silhouette Plot:
   - Muestra qué tan bien agrupada está cada flor.
   - Un valor alto (cerca de 1) significa que la flor está bien ubicada en su grupo.
   - Un valor bajo o negativo sugiere que la flor podría estar en el grupo equivocado.

c) Dendrograma (para Clustering Jerárquico):
   - Es el "árbol genealógico" de las flores.
   - Las ramas muestran cómo se relacionan los grupos entre sí.

## Cómo Interpretar los Resultados

- Mira el Scatter Plot: ¿Ves grupos claros de colores diferentes?
- Revisa el Silhouette Plot: ¿La mayoría de las flores tienen valores altos?
- En el Dendrograma: ¿Puedes ver 3 grandes ramas que podrían representar las 3 especies?

## Consejos Prácticos

- Empieza con K-means y 3 grupos (ya que sabemos que hay 3 especies de Iris).
- Compara con el Clustering Jerárquico para ver si encuentras una estructura similar.
- Usa el Silhouette Plot para verificar qué tan bien funcionó tu agrupación.
- Experimenta cambiando el número de grupos en K-means y observa cómo cambian los resultados.

## Conclusión

El clustering en Orange es como ser un detective de datos. Usas diferentes herramientas (K-means, Clustering Jerárquico) y pistas visuales (Scatter Plot, Silhouette, Dendrograma) para descubrir patrones ocultos en tus datos. Con práctica, podrás aplicar estas técnicas a todo tipo de datos, desde flores hasta comportamientos de clientes o patrones en redes sociales.

Este enfoque te permite explorar tus datos de manera intuitiva y visual, haciendo que conceptos complejos de estadística sean más accesibles y divertidos de aprender.

####################################################################################################################################################

### K-means y esquema jerarquico

K-means es un algoritmo de clustering que divide los datos en K grupos, donde K es un número predefinido.

#### Función:

- Agrupar datos en K clústeres basándose en la similitud de características
- Minimizar la varianza dentro de cada clúster

#### Cómo trabajar con K-means:

- Determinar el número K de clústeres deseados
- Inicializar K centroides aleatoriamente
- Asignar cada punto de datos al centroide más cercano
- Recalcular los centroides basándose en las asignaciones
- Repetir los pasos 3-4 hasta que los centroides se estabilicen

#### Relación entre K-means y clustering jerárquico:

K-means y el clustering jerárquico son enfoques complementarios:

- K-means requiere especificar el número de clústeres de antemano, mientras que el clustering jerárquico construye una jerarquía completa.
- K-means es más rápido para grandes conjuntos de datos, pero el clustering jerárquico proporciona más información sobre la estructura de los datos.

#### Función del esquema jerárquico (dendrograma):

- Visualizar la estructura jerárquica de los datos
- Permitir la exploración de diferentes niveles de agrupamiento
- Identificar subgrupos y relaciones entre clústeres

#### Uso interactivo del esquema jerárquico:

- Ajustar el nivel de corte para obtener diferentes números de clústeres
- Explorar subgrupos dentro de clústeres más grandes
- Comparar la estructura jerárquica con los resultados de K-means para validar la elección del número de clústeres

####################################################################################################################################################

### Silhouette y scatter plot

#### Silhouette:

El Silhouette es una medida de qué tan similar es un objeto a su propio clúster (cohesión) en comparación con otros clústeres (separación).

Representación de la información:
- El eje Y muestra cada instancia de datos.
- El eje X muestra el valor de Silhouette, que va de -1 a 1.

Cómo leer la información:
- Valores cercanos a 1 indican que la instancia está bien emparejada con su clúster.
- Valores cercanos a 0 indican que la instancia está en la frontera entre dos clústeres.
- Valores negativos sugieren que la instancia podría estar en el clúster equivocado.

#### Scatter Plot:

Relación con K-means y clustering jerárquico:
- Visualiza cómo se distribuyen los datos en el espacio bidimensional.
- Muestra los clústeres formados por K-means o los grupos del clustering jerárquico.

Cómo leer la información:
- Cada punto representa una instancia de datos.
- Los colores o formas diferentes indican diferentes clústeres.
- La proximidad entre puntos sugiere similitud.
- Grupos bien definidos y separados indican un buen clustering.

#### Interpretación de ambas visualizaciones:

- Silhouette: Evalúa la calidad del clustering. Un buen clustering tendrá la mayoría de las instancias con valores de Silhouette altos y positivos.
- Scatter Plot: Proporciona una visión intuitiva de cómo se agrupan los datos. Busca grupos bien definidos y separados.

Juntos, ofrecen una visión completa: el Scatter Plot muestra la distribución espacial, mientras que el Silhouette cuantifica qué tan bien se ha realizado el clustering.

#### Otras visualizaciones:

a) Dendrograma (para clustering jerárquico):
   - Muestra la jerarquía de los clústeres.
   - Interpretación: La altura de las conexiones indica la distancia entre clústeres.

b) Heatmap:
   - Visualiza la matriz de distancia entre instancias.
   - Interpretación: Áreas más oscuras indican mayor similitud.

c) PCA (Análisis de Componentes Principales) Plot:
   - Reduce la dimensionalidad de los datos para visualización.
   - Interpretación: Similar al Scatter Plot, pero con datos transformados.

d) t-SNE o UMAP:
   - Técnicas de reducción de dimensionalidad no lineales.
   - Interpretación: Busca agrupaciones en el espacio de baja dimensión.

e) Parallel Coordinates Plot:
   - Muestra múltiples dimensiones en un solo gráfico.
   - Interpretación: Líneas similares indican instancias en el mismo clúster.

Al interpretar estas visualizaciones, busca patrones consistentes entre ellas. Por ejemplo, grupos bien definidos en el Scatter Plot deberían corresponder a altos valores en el Silhouette y a ramas claras en el dendrograma. La combinación de estas visualizaciones proporciona una comprensión más completa de la estructura de tus datos y la calidad del clustering.